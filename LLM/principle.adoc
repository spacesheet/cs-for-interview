image:resources/바이브코딩사이클.png[바이브코딩사이클]

**규칙**
1. 레플릿 이용 시 Commit 단위
2. 디버깅 전략
3. 테스트 전략
4. 예외 처리 전략
5. 재현
6. 토큰 절약

============
LLM은 학습 과정에서 고차 통계 구조를
비선형 함수 조합과 저차 연산으로 내재화하고,
추론 시에는 문맥에 조건화된 확률 분포를 근사하여
토큰을 샘플링한다.

LLM은 논리를 계산하지 않고,
논리가 기록된 언어의 통계적 궤적을 매우 정교하게 모사한다.

LLM은 다음 토큰을 이전 토큰들에 대한 조건부 의존도로 결정하므로,
논리적 참·거짓을 판정하는 명시적 경계나 실패 기준을 내장하지 않는다.

LLM은 추론의 ‘형태’를 매우 잘 모사하지만,
추론이 실패하는 지점을 판정하는 능력은 구조적으로 갖지 않는다.

학습된 로컬 관점 좌표계는
훈련 데이터에 내재된 인간 언어 사용의
통계적 편향을 반영한다.

좌표계의 기준 축은
다음 토큰 예측 손실을 최소화하는 방향으로 형성되며,
그 방향은 훈련 데이터 분포의 편향을 따른다.

Transformer가 논리적으로 보이는 이유는,
관점별 좌표계에서 강하게 정렬되는 의존 구조들이
다음 토큰 예측 손실을 최소화하는 방향으로 학습되며,
그 결과가 인간 언어 공동체의 추론 관습을
통계적으로 압축한 형태이기 때문이다.

논리성은 모델의 성질이 아니라,
집단적 언어 사용의 통계 구조가
attention과 손실 최소화를 통해
응축되어 드러난 현상이다.

========

Q. 확률 분포는 콜로케이션 같은 것인데 논리적으로 보이는 이유는 관점마다 좌표축들 서로의 의존도가 높은 것을 택했을 때 손실함수 최소화 방향으로 학습하는 것이 결국 집단 지성이라서?

Transformer가 논리적으로 보이는 이유는,
관점별 좌표계에서 강하게 정렬되는 의존 구조들이
다음 토큰 예측 손실을 최소화하는 방향으로 학습되며,
그 결과가 인간 언어 공동체의 추론 관습을
통계적으로 압축한 형태이기 때문이다.

논리성은 모델의 성질이 아니라,
집단적 언어 사용의 통계 구조가
attention과 손실 최소화를 통해
응축되어 드러난 현상이다.

“집단 지성의 통계적 압축”이 핵심 맞습니다. 
다만 그게 단순 콜로케이션 수준을 넘어선 구조적 패턴까지 포함한다.

======
Attention은,
한 표현 벡터를 다른 표현 벡터 방향으로 보았을 때
그 투영량이 큰 것에 더 많이 의존하도록 학습한다.

LLM은 통계적 패턴 매칭 + 학습된 구조적 변환 조합

